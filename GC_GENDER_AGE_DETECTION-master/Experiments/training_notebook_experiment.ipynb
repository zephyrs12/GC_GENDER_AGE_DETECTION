{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e5mxjAmkG4ph"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "df = pd.read_csv('UTKFace.csv')\n",
    "\n",
    "\n",
    "df['pixels'] = df['pixels'].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape(48, 48, 1))\n",
    "\n",
    "df['pixels'] = df['pixels'] / 255.0\n",
    "\n",
    "\n",
    "X = np.stack(df['pixels'].values)\n",
    "y_age = df['age'].values\n",
    "y_gender = to_categorical(df['gender'].values)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_age_train, y_age_test, y_gender_train, y_gender_test = train_test_split(X, y_age, y_gender, test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUD8u68MMWQT",
    "outputId": "c5db2129-4f2d-417a-c639-88bd64e78df2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(48, 48, 1))\n",
    "\n",
    "# First block\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# Second block\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "# Flattening and Dense layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "#gender output\n",
    "gender_output = Dense(2, activation='softmax', name='gender_output')(x)  # For gender classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "input_layer2 = Input(shape=(48, 48, 1))\n",
    "\n",
    "# First block\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer2)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D((2, 2))(x1)\n",
    "x1 = Dropout(0.25)(x1)\n",
    "\n",
    "# Second block\n",
    "x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D((2, 2))(x1)\n",
    "x1 = Dropout(0.25)(x1)\n",
    "\n",
    "\n",
    "# Flattening and Dense layers\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(512, activation='relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "# Output layer\n",
    "age_output = Dense(1, activation='relu', name='age_output')(x1)  # For age prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 32)           320       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 48, 48, 32)           320       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 48, 48, 32)           128       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 48, 48, 32)           128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 48, 48, 32)           9248      ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 32)           9248      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 48, 48, 32)           128       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 48, 48, 32)           128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 24, 24, 32)           0         ['batch_normalization_6[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 24, 24, 32)           0         ['batch_normalization_1[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 24, 24, 32)           0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 24, 24, 32)           0         ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 64)           18496     ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)           18496     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 24, 24, 64)           256       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 24, 24, 64)           256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 64)           36928     ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)           36928     ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 24, 24, 64)           256       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 24, 24, 64)           256       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 64)           0         ['batch_normalization_8[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)           0         ['batch_normalization_3[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 12, 12, 64)           0         ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 12, 12, 64)           0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 9216)                 0         ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 9216)                 0         ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 512)                  4719104   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  4719104   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 512)                  2048      ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 512)                  2048      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 512)                  0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 512)                  0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " age_output (Dense)          (None, 1)                    513       ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " gender_output (Dense)       (None, 2)                    1026      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9575363 (36.53 MB)\n",
      "Trainable params: 9572547 (36.52 MB)\n",
      "Non-trainable params: 2816 (11.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_layer, input_layer2], outputs=[age_output, gender_output])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss0Fwg4TMYJK",
    "outputId": "e64dfdbf-7d83-40cc-f08f-3e23b7d57722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "519/519 [==============================] - 266s 507ms/step - loss: 357.8376 - age_output_loss: 357.3891 - gender_output_loss: 0.4485 - age_output_mse: 357.3891 - gender_output_accuracy: 0.8141 - val_loss: 141.0404 - val_age_output_loss: 140.6146 - val_gender_output_loss: 0.4259 - val_age_output_mse: 140.6146 - val_gender_output_accuracy: 0.8145\n",
      "Epoch 2/50\n",
      "519/519 [==============================] - 259s 498ms/step - loss: 131.4013 - age_output_loss: 131.0816 - gender_output_loss: 0.3197 - age_output_mse: 131.0816 - gender_output_accuracy: 0.8625 - val_loss: 98.7117 - val_age_output_loss: 98.4153 - val_gender_output_loss: 0.2964 - val_age_output_mse: 98.4153 - val_gender_output_accuracy: 0.8722\n",
      "Epoch 3/50\n",
      "519/519 [==============================] - 260s 501ms/step - loss: 113.4884 - age_output_loss: 113.2071 - gender_output_loss: 0.2813 - age_output_mse: 113.2071 - gender_output_accuracy: 0.8800 - val_loss: 101.6103 - val_age_output_loss: 101.3200 - val_gender_output_loss: 0.2903 - val_age_output_mse: 101.3200 - val_gender_output_accuracy: 0.8732\n",
      "Epoch 4/50\n",
      "519/519 [==============================] - 256s 493ms/step - loss: 112.8090 - age_output_loss: 112.5469 - gender_output_loss: 0.2622 - age_output_mse: 112.5469 - gender_output_accuracy: 0.8907 - val_loss: 146.7237 - val_age_output_loss: 146.4573 - val_gender_output_loss: 0.2665 - val_age_output_mse: 146.4573 - val_gender_output_accuracy: 0.8864\n",
      "Epoch 5/50\n",
      "519/519 [==============================] - 254s 489ms/step - loss: 108.3519 - age_output_loss: 108.1058 - gender_output_loss: 0.2462 - age_output_mse: 108.1058 - gender_output_accuracy: 0.8936 - val_loss: 97.5718 - val_age_output_loss: 97.3199 - val_gender_output_loss: 0.2519 - val_age_output_mse: 97.3199 - val_gender_output_accuracy: 0.8968\n",
      "Epoch 6/50\n",
      "519/519 [==============================] - 254s 490ms/step - loss: 100.5226 - age_output_loss: 100.2838 - gender_output_loss: 0.2389 - age_output_mse: 100.2838 - gender_output_accuracy: 0.9006 - val_loss: 113.1002 - val_age_output_loss: 112.8269 - val_gender_output_loss: 0.2733 - val_age_output_mse: 112.8269 - val_gender_output_accuracy: 0.8858\n",
      "Epoch 7/50\n",
      "519/519 [==============================] - 257s 496ms/step - loss: 91.7113 - age_output_loss: 91.4935 - gender_output_loss: 0.2178 - age_output_mse: 91.4935 - gender_output_accuracy: 0.9098 - val_loss: 150.4454 - val_age_output_loss: 150.1748 - val_gender_output_loss: 0.2707 - val_age_output_mse: 150.1748 - val_gender_output_accuracy: 0.8886\n",
      "Epoch 8/50\n",
      "519/519 [==============================] - 260s 501ms/step - loss: 87.0721 - age_output_loss: 86.8433 - gender_output_loss: 0.2289 - age_output_mse: 86.8433 - gender_output_accuracy: 0.9066 - val_loss: 103.0308 - val_age_output_loss: 102.7744 - val_gender_output_loss: 0.2564 - val_age_output_mse: 102.7744 - val_gender_output_accuracy: 0.8943\n",
      "Epoch 9/50\n",
      "519/519 [==============================] - 259s 499ms/step - loss: 83.4897 - age_output_loss: 83.2690 - gender_output_loss: 0.2206 - age_output_mse: 83.2690 - gender_output_accuracy: 0.9103 - val_loss: 170.9838 - val_age_output_loss: 170.6377 - val_gender_output_loss: 0.3462 - val_age_output_mse: 170.6377 - val_gender_output_accuracy: 0.8548\n",
      "Epoch 10/50\n",
      "519/519 [==============================] - 257s 496ms/step - loss: 79.7707 - age_output_loss: 79.5762 - gender_output_loss: 0.1945 - age_output_mse: 79.5762 - gender_output_accuracy: 0.9211 - val_loss: 91.7253 - val_age_output_loss: 91.0823 - val_gender_output_loss: 0.6431 - val_age_output_mse: 91.0823 - val_gender_output_accuracy: 0.8055\n",
      "Epoch 11/50\n",
      "519/519 [==============================] - 258s 496ms/step - loss: 81.2451 - age_output_loss: 81.0582 - gender_output_loss: 0.1869 - age_output_mse: 81.0582 - gender_output_accuracy: 0.9255 - val_loss: 78.4972 - val_age_output_loss: 77.8771 - val_gender_output_loss: 0.6201 - val_age_output_mse: 77.8771 - val_gender_output_accuracy: 0.8352\n",
      "Epoch 12/50\n",
      "519/519 [==============================] - 257s 495ms/step - loss: 77.8009 - age_output_loss: 77.6177 - gender_output_loss: 0.1831 - age_output_mse: 77.6177 - gender_output_accuracy: 0.9236 - val_loss: 84.3826 - val_age_output_loss: 84.1182 - val_gender_output_loss: 0.2643 - val_age_output_mse: 84.1182 - val_gender_output_accuracy: 0.9047\n",
      "Epoch 13/50\n",
      "519/519 [==============================] - 255s 492ms/step - loss: 74.8960 - age_output_loss: 74.7329 - gender_output_loss: 0.1631 - age_output_mse: 74.7329 - gender_output_accuracy: 0.9346 - val_loss: 79.0372 - val_age_output_loss: 78.7841 - val_gender_output_loss: 0.2530 - val_age_output_mse: 78.7841 - val_gender_output_accuracy: 0.9080\n",
      "Epoch 14/50\n",
      "519/519 [==============================] - 254s 490ms/step - loss: 90.0294 - age_output_loss: 89.8600 - gender_output_loss: 0.1693 - age_output_mse: 89.8600 - gender_output_accuracy: 0.9327 - val_loss: 124.7401 - val_age_output_loss: 124.4781 - val_gender_output_loss: 0.2620 - val_age_output_mse: 124.4781 - val_gender_output_accuracy: 0.8988\n",
      "Epoch 15/50\n",
      "519/519 [==============================] - 253s 488ms/step - loss: 83.2835 - age_output_loss: 83.1337 - gender_output_loss: 0.1497 - age_output_mse: 83.1337 - gender_output_accuracy: 0.9403 - val_loss: 81.7961 - val_age_output_loss: 81.5468 - val_gender_output_loss: 0.2493 - val_age_output_mse: 81.5468 - val_gender_output_accuracy: 0.9038\n",
      "Epoch 16/50\n",
      "519/519 [==============================] - 256s 494ms/step - loss: 72.7225 - age_output_loss: 72.5871 - gender_output_loss: 0.1353 - age_output_mse: 72.5871 - gender_output_accuracy: 0.9454 - val_loss: 74.7329 - val_age_output_loss: 74.5007 - val_gender_output_loss: 0.2321 - val_age_output_mse: 74.5007 - val_gender_output_accuracy: 0.9113\n",
      "Epoch 17/50\n",
      "519/519 [==============================] - 257s 495ms/step - loss: 67.8413 - age_output_loss: 67.7190 - gender_output_loss: 0.1223 - age_output_mse: 67.7190 - gender_output_accuracy: 0.9543 - val_loss: 82.5022 - val_age_output_loss: 82.2123 - val_gender_output_loss: 0.2899 - val_age_output_mse: 82.2123 - val_gender_output_accuracy: 0.8955\n",
      "Epoch 18/50\n",
      "519/519 [==============================] - 257s 496ms/step - loss: 65.8189 - age_output_loss: 65.6986 - gender_output_loss: 0.1203 - age_output_mse: 65.6986 - gender_output_accuracy: 0.9534 - val_loss: 75.5795 - val_age_output_loss: 75.3121 - val_gender_output_loss: 0.2674 - val_age_output_mse: 75.3121 - val_gender_output_accuracy: 0.9057\n",
      "Epoch 19/50\n",
      "519/519 [==============================] - 257s 494ms/step - loss: 66.5794 - age_output_loss: 66.4537 - gender_output_loss: 0.1256 - age_output_mse: 66.4537 - gender_output_accuracy: 0.9496 - val_loss: 105.8831 - val_age_output_loss: 105.5501 - val_gender_output_loss: 0.3330 - val_age_output_mse: 105.5501 - val_gender_output_accuracy: 0.8971\n",
      "Epoch 20/50\n",
      "519/519 [==============================] - 255s 491ms/step - loss: 65.8683 - age_output_loss: 65.7419 - gender_output_loss: 0.1265 - age_output_mse: 65.7419 - gender_output_accuracy: 0.9515 - val_loss: 84.3426 - val_age_output_loss: 84.0707 - val_gender_output_loss: 0.2718 - val_age_output_mse: 84.0707 - val_gender_output_accuracy: 0.9059\n",
      "Epoch 21/50\n",
      "519/519 [==============================] - 254s 490ms/step - loss: 64.1066 - age_output_loss: 63.9929 - gender_output_loss: 0.1138 - age_output_mse: 63.9929 - gender_output_accuracy: 0.9575 - val_loss: 85.8035 - val_age_output_loss: 85.5415 - val_gender_output_loss: 0.2619 - val_age_output_mse: 85.5415 - val_gender_output_accuracy: 0.9109\n",
      "Epoch 22/50\n",
      "519/519 [==============================] - 255s 491ms/step - loss: 62.9666 - age_output_loss: 62.8554 - gender_output_loss: 0.1111 - age_output_mse: 62.8554 - gender_output_accuracy: 0.9570 - val_loss: 74.0176 - val_age_output_loss: 73.7248 - val_gender_output_loss: 0.2928 - val_age_output_mse: 73.7248 - val_gender_output_accuracy: 0.9021\n",
      "Epoch 23/50\n",
      "519/519 [==============================] - 256s 494ms/step - loss: 62.0811 - age_output_loss: 61.9655 - gender_output_loss: 0.1156 - age_output_mse: 61.9655 - gender_output_accuracy: 0.9553 - val_loss: 102.8928 - val_age_output_loss: 102.5887 - val_gender_output_loss: 0.3041 - val_age_output_mse: 102.5887 - val_gender_output_accuracy: 0.8982\n",
      "Epoch 24/50\n",
      "519/519 [==============================] - 257s 496ms/step - loss: 60.5737 - age_output_loss: 60.4752 - gender_output_loss: 0.0986 - age_output_mse: 60.4752 - gender_output_accuracy: 0.9629 - val_loss: 74.2235 - val_age_output_loss: 73.9443 - val_gender_output_loss: 0.2792 - val_age_output_mse: 73.9443 - val_gender_output_accuracy: 0.9102\n",
      "Epoch 25/50\n",
      "519/519 [==============================] - 257s 496ms/step - loss: 59.2807 - age_output_loss: 59.1854 - gender_output_loss: 0.0952 - age_output_mse: 59.1854 - gender_output_accuracy: 0.9645 - val_loss: 267.8009 - val_age_output_loss: 267.5021 - val_gender_output_loss: 0.2988 - val_age_output_mse: 267.5021 - val_gender_output_accuracy: 0.9106\n",
      "Epoch 26/50\n",
      "519/519 [==============================] - 273s 527ms/step - loss: 60.7389 - age_output_loss: 60.6496 - gender_output_loss: 0.0893 - age_output_mse: 60.6496 - gender_output_accuracy: 0.9673 - val_loss: 885.4898 - val_age_output_loss: 885.1124 - val_gender_output_loss: 0.3771 - val_age_output_mse: 885.1124 - val_gender_output_accuracy: 0.8882\n",
      "Epoch 27/50\n",
      "519/519 [==============================] - 286s 552ms/step - loss: 61.3322 - age_output_loss: 61.2315 - gender_output_loss: 0.1007 - age_output_mse: 61.2315 - gender_output_accuracy: 0.9637 - val_loss: 84.0242 - val_age_output_loss: 83.6337 - val_gender_output_loss: 0.3904 - val_age_output_mse: 83.6337 - val_gender_output_accuracy: 0.8816\n",
      "Epoch 28/50\n",
      "519/519 [==============================] - 277s 533ms/step - loss: 56.4751 - age_output_loss: 56.3442 - gender_output_loss: 0.1310 - age_output_mse: 56.3442 - gender_output_accuracy: 0.9493 - val_loss: 105.5934 - val_age_output_loss: 105.2933 - val_gender_output_loss: 0.3001 - val_age_output_mse: 105.2933 - val_gender_output_accuracy: 0.9044\n",
      "Epoch 29/50\n",
      "519/519 [==============================] - 267s 515ms/step - loss: 58.6979 - age_output_loss: 58.6059 - gender_output_loss: 0.0921 - age_output_mse: 58.6059 - gender_output_accuracy: 0.9650 - val_loss: 93.9450 - val_age_output_loss: 93.6637 - val_gender_output_loss: 0.2812 - val_age_output_mse: 93.6637 - val_gender_output_accuracy: 0.9117\n",
      "Epoch 30/50\n",
      "519/519 [==============================] - 268s 517ms/step - loss: 53.3439 - age_output_loss: 53.2605 - gender_output_loss: 0.0834 - age_output_mse: 53.2605 - gender_output_accuracy: 0.9700 - val_loss: 90.7692 - val_age_output_loss: 90.4755 - val_gender_output_loss: 0.2937 - val_age_output_mse: 90.4755 - val_gender_output_accuracy: 0.9054\n",
      "Epoch 31/50\n",
      "519/519 [==============================] - 277s 533ms/step - loss: 55.2013 - age_output_loss: 55.1264 - gender_output_loss: 0.0749 - age_output_mse: 55.1264 - gender_output_accuracy: 0.9712 - val_loss: 389.1631 - val_age_output_loss: 388.8343 - val_gender_output_loss: 0.3286 - val_age_output_mse: 388.8343 - val_gender_output_accuracy: 0.9027\n",
      "Epoch 32/50\n",
      "519/519 [==============================] - 286s 552ms/step - loss: 54.1690 - age_output_loss: 54.1027 - gender_output_loss: 0.0663 - age_output_mse: 54.1027 - gender_output_accuracy: 0.9752 - val_loss: 173.5520 - val_age_output_loss: 173.2548 - val_gender_output_loss: 0.2972 - val_age_output_mse: 173.2548 - val_gender_output_accuracy: 0.9135\n",
      "Epoch 33/50\n",
      "519/519 [==============================] - 282s 544ms/step - loss: 51.4158 - age_output_loss: 51.3443 - gender_output_loss: 0.0715 - age_output_mse: 51.3443 - gender_output_accuracy: 0.9739 - val_loss: 75.0136 - val_age_output_loss: 74.2348 - val_gender_output_loss: 0.7788 - val_age_output_mse: 74.2348 - val_gender_output_accuracy: 0.8368\n",
      "Epoch 34/50\n",
      "519/519 [==============================] - 282s 544ms/step - loss: 52.9584 - age_output_loss: 52.8528 - gender_output_loss: 0.1056 - age_output_mse: 52.8528 - gender_output_accuracy: 0.9596 - val_loss: 202.8408 - val_age_output_loss: 202.5407 - val_gender_output_loss: 0.3000 - val_age_output_mse: 202.5407 - val_gender_output_accuracy: 0.9127\n",
      "Epoch 35/50\n",
      "519/519 [==============================] - 282s 544ms/step - loss: 51.6138 - age_output_loss: 51.5408 - gender_output_loss: 0.0729 - age_output_mse: 51.5408 - gender_output_accuracy: 0.9725 - val_loss: 183.1733 - val_age_output_loss: 182.8687 - val_gender_output_loss: 0.3047 - val_age_output_mse: 182.8687 - val_gender_output_accuracy: 0.9090\n",
      "Epoch 36/50\n",
      "519/519 [==============================] - 281s 541ms/step - loss: 52.2300 - age_output_loss: 52.1641 - gender_output_loss: 0.0660 - age_output_mse: 52.1641 - gender_output_accuracy: 0.9747 - val_loss: 80.6000 - val_age_output_loss: 80.3074 - val_gender_output_loss: 0.2927 - val_age_output_mse: 80.3074 - val_gender_output_accuracy: 0.9135\n",
      "Epoch 37/50\n",
      "519/519 [==============================] - 278s 535ms/step - loss: 51.7031 - age_output_loss: 51.6273 - gender_output_loss: 0.0757 - age_output_mse: 51.6273 - gender_output_accuracy: 0.9719 - val_loss: 129.7666 - val_age_output_loss: 129.4559 - val_gender_output_loss: 0.3107 - val_age_output_mse: 129.4559 - val_gender_output_accuracy: 0.9151\n",
      "Epoch 38/50\n",
      "519/519 [==============================] - 266s 513ms/step - loss: 52.1317 - age_output_loss: 52.0738 - gender_output_loss: 0.0580 - age_output_mse: 52.0738 - gender_output_accuracy: 0.9779 - val_loss: 82.3614 - val_age_output_loss: 82.0481 - val_gender_output_loss: 0.3133 - val_age_output_mse: 82.0481 - val_gender_output_accuracy: 0.9175\n",
      "Epoch 39/50\n",
      "519/519 [==============================] - 261s 502ms/step - loss: 51.4840 - age_output_loss: 51.4286 - gender_output_loss: 0.0554 - age_output_mse: 51.4286 - gender_output_accuracy: 0.9802 - val_loss: 86.8296 - val_age_output_loss: 86.4411 - val_gender_output_loss: 0.3884 - val_age_output_mse: 86.4411 - val_gender_output_accuracy: 0.8944\n",
      "Epoch 40/50\n",
      "519/519 [==============================] - 258s 498ms/step - loss: 48.7693 - age_output_loss: 48.7138 - gender_output_loss: 0.0555 - age_output_mse: 48.7138 - gender_output_accuracy: 0.9797 - val_loss: 84.4776 - val_age_output_loss: 84.1524 - val_gender_output_loss: 0.3252 - val_age_output_mse: 84.1524 - val_gender_output_accuracy: 0.9124\n",
      "Epoch 41/50\n",
      "519/519 [==============================] - 259s 499ms/step - loss: 49.7711 - age_output_loss: 49.6937 - gender_output_loss: 0.0774 - age_output_mse: 49.6937 - gender_output_accuracy: 0.9712 - val_loss: 73.7866 - val_age_output_loss: 73.4714 - val_gender_output_loss: 0.3152 - val_age_output_mse: 73.4714 - val_gender_output_accuracy: 0.9114\n",
      "Epoch 42/50\n",
      "519/519 [==============================] - 260s 500ms/step - loss: 48.1721 - age_output_loss: 48.1105 - gender_output_loss: 0.0617 - age_output_mse: 48.1105 - gender_output_accuracy: 0.9778 - val_loss: 79.3234 - val_age_output_loss: 78.9916 - val_gender_output_loss: 0.3318 - val_age_output_mse: 78.9916 - val_gender_output_accuracy: 0.9116\n",
      "Epoch 43/50\n",
      "519/519 [==============================] - 259s 499ms/step - loss: 49.9935 - age_output_loss: 49.9357 - gender_output_loss: 0.0578 - age_output_mse: 49.9357 - gender_output_accuracy: 0.9788 - val_loss: 74.3526 - val_age_output_loss: 74.0481 - val_gender_output_loss: 0.3044 - val_age_output_mse: 74.0481 - val_gender_output_accuracy: 0.9107\n",
      "Epoch 44/50\n",
      "519/519 [==============================] - 258s 498ms/step - loss: 48.4612 - age_output_loss: 48.4050 - gender_output_loss: 0.0562 - age_output_mse: 48.4050 - gender_output_accuracy: 0.9791 - val_loss: 115.3814 - val_age_output_loss: 115.0820 - val_gender_output_loss: 0.2995 - val_age_output_mse: 115.0820 - val_gender_output_accuracy: 0.9130\n",
      "Epoch 45/50\n",
      "519/519 [==============================] - 265s 511ms/step - loss: 47.4961 - age_output_loss: 47.4336 - gender_output_loss: 0.0625 - age_output_mse: 47.4336 - gender_output_accuracy: 0.9772 - val_loss: 174.0256 - val_age_output_loss: 173.6823 - val_gender_output_loss: 0.3434 - val_age_output_mse: 173.6823 - val_gender_output_accuracy: 0.9028\n",
      "Epoch 46/50\n",
      "519/519 [==============================] - 263s 506ms/step - loss: 45.9298 - age_output_loss: 45.8699 - gender_output_loss: 0.0599 - age_output_mse: 45.8699 - gender_output_accuracy: 0.9775 - val_loss: 72.1094 - val_age_output_loss: 71.7925 - val_gender_output_loss: 0.3169 - val_age_output_mse: 71.7925 - val_gender_output_accuracy: 0.9118\n",
      "Epoch 47/50\n",
      "519/519 [==============================] - 266s 513ms/step - loss: 46.3596 - age_output_loss: 46.2763 - gender_output_loss: 0.0832 - age_output_mse: 46.2763 - gender_output_accuracy: 0.9695 - val_loss: 73.5892 - val_age_output_loss: 73.2460 - val_gender_output_loss: 0.3432 - val_age_output_mse: 73.2460 - val_gender_output_accuracy: 0.8972\n",
      "Epoch 48/50\n",
      "519/519 [==============================] - 263s 507ms/step - loss: 46.9226 - age_output_loss: 46.8431 - gender_output_loss: 0.0795 - age_output_mse: 46.8431 - gender_output_accuracy: 0.9714 - val_loss: 72.7341 - val_age_output_loss: 72.4170 - val_gender_output_loss: 0.3170 - val_age_output_mse: 72.4170 - val_gender_output_accuracy: 0.9087\n",
      "Epoch 49/50\n",
      "519/519 [==============================] - 260s 500ms/step - loss: 47.6629 - age_output_loss: 47.5926 - gender_output_loss: 0.0702 - age_output_mse: 47.5926 - gender_output_accuracy: 0.9740 - val_loss: 73.1367 - val_age_output_loss: 72.8253 - val_gender_output_loss: 0.3114 - val_age_output_mse: 72.8253 - val_gender_output_accuracy: 0.9097\n",
      "Epoch 50/50\n",
      "519/519 [==============================] - 263s 507ms/step - loss: 44.5906 - age_output_loss: 44.5259 - gender_output_loss: 0.0647 - age_output_mse: 44.5259 - gender_output_accuracy: 0.9757 - val_loss: 74.0624 - val_age_output_loss: 73.7511 - val_gender_output_loss: 0.3113 - val_age_output_mse: 73.7511 - val_gender_output_accuracy: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1df5c9f5f50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mse', 'gender_output': 'binary_crossentropy'},\n",
    "              metrics={'age_output': 'mse', 'gender_output': 'accuracy'})\n",
    "\n",
    "model.fit([X_train,X_train], {'age_output': y_age_train, 'gender_output': y_gender_train},\n",
    "          validation_data=([X_test,X_test], {'age_output': y_age_test, 'gender_output': y_gender_test}),\n",
    "          epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('gen_age_2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsjCPTD_QbkO",
    "outputId": "bc4a2342-90cd-4955-e765-a8f1e9270dc6"
   },
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
